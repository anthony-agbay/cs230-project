{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging and Final Processing\n",
    "\n",
    "This notebook contains code to prepare and clean original dataset for machine learning applications (one-hot encodings, removal of missing or incorrect values, etc.) and merging with FEATURE vector data for the final combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions and Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mapping from Protein Name to PDB Structure ###\n",
    "prot_pdb_dict = {'TEM-1': '1xpb',\n",
    "                 'Kka2': '1nd4',\n",
    "                 'Uba1': '3cmm',\n",
    "                 'PSD95pdz3': '1be9',\n",
    "                 'Pab1': '1cvj',\n",
    "                 'Yap65': '1jmq',\n",
    "                 'hsp90': '2cg9',\n",
    "                 'gb1': '1pga'\n",
    "                }\n",
    "\n",
    "def prot_to_pdb(row):\n",
    "    \"\"\" Maps protein identifier to PDB accession number to create new column\n",
    "    \"\"\"\n",
    "\n",
    "    return(prot_pdb_dict[row['protein']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Read\n",
    "main_data_path = 'data/mmc2.csv'\n",
    "main_data = pd.read_csv(main_data_path)\n",
    "\n",
    "# Filter out \"predicted\" variant effects from original dataset\n",
    "main_data = main_data[main_data['predicted?'] == 'NO']\n",
    "\n",
    "# Dropping Unnecessary ID columns\n",
    "main_data.drop(['variant_id', 'position_id', 'dms_id', 'uniprot', 'predicted?'], axis=1, inplace=True)\n",
    "\n",
    "## Parsing and Renaming columns\n",
    "main_data['pdb'] = main_data.apply(lambda row: prot_to_pdb(row), axis=1)\n",
    "main_data.rename(columns = {'position':'resnum'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Redundant or Columns with too much Missing Data\n",
    "main_data.drop(['local_density', 'local_biochem', 'predictions', 'selection_coefficient', 'local_conservation'],axis=1, inplace=True)\n",
    "\n",
    "# Fix Data Errors\n",
    "main_data['accessibility'].fillna(0, inplace=True)\n",
    "main_data['dssp_sec_str'].replace('.', 'O', inplace=True)\n",
    "main_data['dssp_sec_str'].fillna('O', inplace=True)\n",
    "main_data['phi_psi_reg'].fillna('O', inplace=True)\n",
    "main_data['wt_mut'].fillna('NA', inplace=True)\n",
    "main_data['evolutionary_coupling_avg'].fillna(0, inplace=True)\n",
    "main_data['mut_msa_congruency'].fillna(1.4, inplace=True)\n",
    "main_data['mut_mut_msa_congruency'].fillna(0.04, inplace=True)\n",
    "main_data['seq_ind_closest_mut'].fillna(0,inplace=True)\n",
    "main_data['b_factor'].fillna(0,inplace=True)\n",
    "main_data['delta_solvent_accessibility'].fillna(0, inplace=True)\n",
    "main_data.dropna(subset=['grantham'], inplace=True)\n",
    "main_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEM-1' 'Kka2' 'Uba1' 'PSD95pdz3' 'Pab1' 'Yap65' 'hsp90' 'gb1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52922, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(main_data.protein.unique())\n",
    "main_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering and cleaning data, all proteins were retained, leaving 52,922 samples to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataset Encoding\n",
    "After cleaning, now need to one-hot encode any categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_encode = pd.get_dummies(main_data,columns=['aa1', 'aa2', 'wt_mut', 'aa1_polarity', 'aa2_polarity', 'dssp_sec_str', 'phi_psi_reg'])\n",
    "main_encode.shape\n",
    "main_encode.to_csv('data/mmc2_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging with FEATURE Vectors\n",
    "Next will merge with FEATURE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49581, 971)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = pd.read_csv('data/feature-files/feature_merged.csv')\n",
    "# merged_data = pd.merge(main_encode, feature_data, on=['pdb', 'resnum'], how='left') # Add on left to duplicate microenvironments\n",
    "merged_data = pd.merge(main_encode, feature_data, on=['pdb', 'resnum'])\n",
    "merged_data.drop(['Unnamed: 0', 'Unnamed: 1'], axis=1, inplace=True)\n",
    "merged_data.to_csv('data/merged.csv')\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1xpb', '1nd4', '3cmm', '1be9', '1cvj', '2cg9'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.pdb.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
