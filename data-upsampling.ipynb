{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling\n",
    "\n",
    "From baseline neural network models and initial hyperparameter search, the initial imbalance was shown to create major problems. To address this, we will upsample data *within each protein* to create balanced deleterious-beneficial-neutral distribution.\n",
    "\n",
    "From the initial hyperparameter search, we will use 0.05 as the threshold offset going forward. This is a better balance for performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Data\n",
    "data = pd.read_csv('data/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49581, 113)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the conversion to Categorical and prep\n",
    "def label_type(row):\n",
    "    if row['scaled_effect'] < .9:\n",
    "        return('Deleterious')\n",
    "    elif row['scaled_effect'] > 1.1:\n",
    "        return('Beneficial')\n",
    "    else:\n",
    "        return('Neutral')\n",
    "\n",
    "# Convert to categorical characterization\n",
    "data['type'] = data.apply(lambda row: label_type(row), axis=1)\n",
    "processed_data = data.drop(['scaled_effect'], axis=1)\n",
    "\n",
    "# Get Unique proteins\n",
    "proteins = processed_data.protein.unique()\n",
    "\n",
    "# Final Upsampled Data Structure\n",
    "upsampled_data = pd.DataFrame(columns = processed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEM-1\n",
      "Del Samples: 9735\n",
      "Ben Resampled: 9735\n",
      "Neut Resampled: 9735\n",
      "Kka2\n",
      "Del Samples: 12120\n",
      "Ben Resampled: 12120\n",
      "Neut Resampled: 12120\n",
      "Uba1\n",
      "Del Samples: 528\n",
      "Neut Resampled: 528\n",
      "PSD95pdz3\n",
      "Del Samples: 436\n",
      "Ben Resampled: 436\n",
      "Neut Resampled: 436\n",
      "Pab1\n",
      "Del Samples: 404\n",
      "Neut Resampled: 404\n",
      "hsp90\n",
      "Del Samples: 109\n",
      "Neut Resampled: 109\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    prot_data = processed_data[processed_data.protein == protein]\n",
    "    print(protein)\n",
    "    \n",
    "    del_samples = prot_data[prot_data.type == 'Deleterious']\n",
    "    num_del_samples = del_samples.shape[0]\n",
    "    print(\"Del Samples: \" + str(num_del_samples))\n",
    "    upsampled_data = pd.concat([upsampled_data, del_samples])\n",
    "    \n",
    "    ben_samples = prot_data[prot_data.type == 'Beneficial']\n",
    "    neut_samples = prot_data[prot_data.type == 'Neutral']\n",
    "    \n",
    "    # Upsample -- Deleterious is *always* larger\n",
    "    if ben_samples.shape[0] != 0:\n",
    "        ben_resampled = resample(ben_samples,\n",
    "                                 replace=True,\n",
    "                                 n_samples = num_del_samples)\n",
    "        upsampled_data = pd.concat([upsampled_data, ben_resampled])\n",
    "        print(\"Ben Resampled: \" + str(ben_resampled.shape[0]))\n",
    "    \n",
    "    if neut_samples.shape[0] != 0:\n",
    "        neut_resampled = resample(neut_samples,\n",
    "                                 replace=True,\n",
    "                                 n_samples = num_del_samples)\n",
    "        upsampled_data = pd.concat([upsampled_data, neut_resampled])\n",
    "        print(\"Neut Resampled: \" + str(neut_resampled.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_data.to_csv('data/upsampled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68955, 112)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
